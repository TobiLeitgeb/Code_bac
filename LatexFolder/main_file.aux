\relax 
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{english}{}
\citation{RasmussenCarlEdward}
\citation{RasmussenCarlEdward}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Fundamentals}{2}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Gaussian Process}{2}{subsection.2.1}\protected@file@percent }
\newlabel{eq:f_star_random_vector}{{4}{2}{Gaussian Process}{equation.2.4}{}}
\citation{bishop}
\citation{RasmussenCarlEdward}
\citation{RasmussenCarlEdward}
\citation{Duvenaud}
\citation{görtler2019a}
\citation{RasmussenCarlEdward}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Regression}{3}{subsection.2.2}\protected@file@percent }
\newlabel{sec:Regression}{{2.2}{3}{Regression}{subsection.2.2}{}}
\newlabel{eq:joint_f,X_*}{{6}{3}{Regression}{equation.2.6}{}}
\newlabel{eq:general_kernel}{{7}{3}{Regression}{equation.2.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Kernels}{3}{subsection.2.3}\protected@file@percent }
\citation{RasmussenCarlEdward}
\citation{RAISSI}
\citation{RasmussenCarlEdward}
\citation{garnett_2023_full}
\citation{Särkkä}
\citation{RAISSI}
\citation{garnett_2023_full}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Marginal likelihood}{4}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Linear operators and GPs}{4}{subsection.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Physics informed framework}{4}{section.3}\protected@file@percent }
\newlabel{eq:Lu=f}{{12}{4}{Physics informed framework}{equation.3.12}{}}
\newlabel{eq:jointGP}{{17}{4}{Physics informed framework}{equation.3.17}{}}
\citation{Singer:2009NelderMead}
\citation{RAISSI}
\newlabel{eq:jointGP_observations}{{19}{5}{Physics informed framework}{equation.3.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Optimization/Finding of the hyperparameters}{5}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Predictions with the Posterior}{5}{subsection.3.2}\protected@file@percent }
\citation{RasmussenCarlEdward}
\citation{RAISSI}
\citation{gpy2014}
\newlabel{eq:predictive_mean_cov}{{22}{6}{Predictions with the Posterior}{equation.3.22}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{6}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Damped oscillator}{7}{subsection.4.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces MSEs for the informed model with different number of training points $n$. The used noise was $\sigma _{nu} = $ and $\sigma _{nf}$.}}{7}{table.caption.2}\protected@file@percent }
\newlabel{tab:variing_n_trainingpoints}{{1}{7}{MSEs for the informed model with different number of training points $n$. The used noise was $\sigma _{nu} = $ and $\sigma _{nf}$}{table.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Heat Equation}{7}{subsection.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces (a) \& (b) predictive mean $\mu _u$ and $\mu _f$ for the informed model, two $\sigma $ uncertanty band, training and validation points sampled from $\{\bm  {x_u},u(\bm  {y_u})\}$ and $\{\bm  {x_f},u(\bm  {y_f})\}$ respectivly.\ (c) \& (d) predictive mean $\mu _u$ and $\mu _f$ for the vanilla model, two $\sigma $ uncertanty band, training and validation points sampled from $\{\bm  {x_u},u(\bm  {y_u})\}$ and $\{\bm  {x_f},u(\bm  {y_f})\}$ respectivly. The noise $\sigma _{nu}$ and $\sigma _{nf}$ were both set to $10^{-8}$. The MSEs of the informed model are $MSE_u = 1.419 \cdot 10^{-7}$ and $MSE_f = 4.609 \cdot 10^{-3}$. The MSEs for the vanilla model are $MSE_{u,va} = 5.469 \cdot 10^{-4}$ and $MSE_{f,va} = 2.692$.}}{8}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:damped_oscillator}{{1}{8}{(a) \& (b) predictive mean $\mu _u$ and $\mu _f$ for the informed model, two $\sigma $ uncertanty band, training and validation points sampled from $\{\bm {x_u},u(\bm {y_u})\}$ and $\{\bm {x_f},u(\bm {y_f})\}$ respectivly.\ (c) \& (d) predictive mean $\mu _u$ and $\mu _f$ for the vanilla model, two $\sigma $ uncertanty band, training and validation points sampled from $\{\bm {x_u},u(\bm {y_u})\}$ and $\{\bm {x_f},u(\bm {y_f})\}$ respectivly. The noise $\sigma _{nu}$ and $\sigma _{nf}$ were both set to $10^{-8}$. The MSEs of the informed model are $MSE_u = 1.419 \cdot 10^{-7}$ and $MSE_f = 4.609 \cdot 10^{-3}$. The MSEs for the vanilla model are $MSE_{u,va} = 5.469 \cdot 10^{-4}$ and $MSE_{f,va} = 2.692$}{figure.caption.1}{}}
\bibstyle{plain}
\bibdata{library}
\bibcite{bishop}{1}
\bibcite{Duvenaud}{2}
\bibcite{garnett_2023_full}{3}
\bibcite{gpy2014}{4}
\bibcite{görtler2019a}{5}
\bibcite{RAISSI}{6}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Wave Equation}{9}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Poisson Equation}{9}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion and Outlook}{9}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Appendix}{9}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Numerical implementation of the Kernel}{9}{subsection.6.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Plots for the informed model. (a) \& (b) predictive mean $\bm  {\mu _u}$ and $\bm  {\mu _f}$ with training points in red. (c) \& (d) predictive standard deviations $\bm  {\sigma _u}$ and $\bm  {\sigma _f}$. (e) \& (f) difference between the predictive mean $\bm  {\mu }$ and the ground truths $u$ and $f$. The MSEs for the informed model are $MSE_u = \cdot 10^{-7}$ and $MSE_f = \cdot 10^{-3}$. The relative $L²$ errors are $L²_u = $ and $L²_f = $.}}{10}{figure.caption.3}\protected@file@percent }
\newlabel{fig:poisson}{{2}{10}{Plots for the informed model. (a) \& (b) predictive mean $\bm {\mu _u}$ and $\bm {\mu _f}$ with training points in red. (c) \& (d) predictive standard deviations $\bm {\sigma _u}$ and $\bm {\sigma _f}$. (e) \& (f) difference between the predictive mean $\bm {\mu }$ and the ground truths $u$ and $f$. The MSEs for the informed model are $MSE_u = \cdot 10^{-7}$ and $MSE_f = \cdot 10^{-3}$. The relative $L²$ errors are $L²_u = $ and $L²_f = $}{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Plots for the vanilla model. (a) \& (b) predictive mean $\bm  {\mu _u}$ and $\bm  {\mu _f}$}}{11}{figure.caption.4}\protected@file@percent }
\newlabel{fig:poisson_GPY}{{3}{11}{Plots for the vanilla model. (a) \& (b) predictive mean $\bm {\mu _u}$ and $\bm {\mu _f}$}{figure.caption.4}{}}
\bibcite{RasmussenCarlEdward}{7}
\bibcite{Singer:2009NelderMead}{8}
\bibcite{Särkkä}{9}
\gdef \@abspage@last{12}
